{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from scipy.stats import kurtosis, skew                                          #檢驗殘差常態性\n",
    "from statsmodels.stats.stattools import durbin_watson                           #檢驗殘差變異數獨立性\n",
    "from sklearn import preprocessing                                               #檢驗變異數同值性\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor      #檢驗共線性\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/chouhouren/Desktop/論文資料_新/建模型資料/df_直線模型.xlsx\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feture =[]\n",
    "feture = df.drop(['新總價','編號'], axis=1)\n",
    "x = feture\n",
    "y = df.新總價"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(x, y, \n",
    "                       initial_list=[],\n",
    "                       vif_value=[],\n",
    "                       threshold_in=0.05, \n",
    "                       threshold_out = 0.1, \n",
    "                       vif_out=10,\n",
    "                       verbose=True):\n",
    "    \n",
    "    included = list(x.columns)\n",
    "    vif_too_big=list(vif_value)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(x.columns)-set(included)-set(vif_too_big))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        \n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose: \n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "            \n",
    "        vif_constant = sm.add_constant(x[included])        \n",
    "        f_vif=[variance_inflation_factor(vif_constant.values, j) for j in range(vif_constant.shape[1])]\n",
    "        f_vif=pd.Series(f_vif,index=vif_constant.columns)\n",
    "        f_vif=f_vif.iloc[1:]\n",
    "        big_vif = f_vif.max()\n",
    "            \n",
    "            \n",
    "        if big_vif > vif_out:\n",
    "            changed=True\n",
    "            big_vif_feature = f_vif.idxmax()\n",
    "            included.remove(big_vif_feature)\n",
    "            vif_too_big.append(big_vif_feature)\n",
    "            #if verbose:\n",
    "                #print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        \n",
    "         \n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(x, y)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sma.add_constant(df[result]) ## let's add an intercept (beta_0) to our model\n",
    "\n",
    "lm2 = sm.OLS(y,x_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常態性假設檢驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=y-lm2.fittedvalues\n",
    "resid_skew = skew(e)\n",
    "resid_kurtosis = kurtosis(e)\n",
    "print('{:40}{:.5}'.format('skewness of normal distribution:',resid_skew ))\n",
    "print('{:40}{:.5}'.format('kurtosis of normal distribution:',resid_kurtosis ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 獨立性假設檢驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dw(data):\n",
    "    ols_res = OLS(data, np.ones(len(data))).fit()\n",
    "    return durbin_watson(ols_res.resid)\n",
    "\n",
    "\n",
    "print('{:20}{:.5}'.format('Durbin-Watson:',dw(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 變異數同值性假設檢驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm=preprocessing.scale(lm2.fittedvalues)\n",
    "\n",
    "e_norm =preprocessing.scale(e)\n",
    "\n",
    "\n",
    "plt.scatter(y_pred_norm, e_norm,color='k',marker='o')\n",
    "plt.xlabel(\"Standardized Predicted Value\")\n",
    "plt.ylabel(\"Standardized Residual\")\n",
    "plt.axhline(y=0,linewidth=3, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 無共線性檢驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif=[variance_inflation_factor(x_train.values, j) for j in range(x_train.shape[1])]\n",
    "vif=pd.DataFrame(vif,index=x_train.columns,columns=['VIF'])\n",
    "\n",
    "\n",
    "vif=vif.drop(['const'])\n",
    "if vif['VIF'].max() <10:\n",
    "    print('no collinarity')\n",
    "else:\n",
    "    print(vif['VIF'].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = pd.DataFrame(lm2.tvalues,columns=['p_value'])\n",
    "\n",
    "coef = pd.DataFrame(lm2.params,columns=['coef'])\n",
    "\n",
    "vif=[variance_inflation_factor(x_train.values, j) for j in range(x_train.shape[1])]\n",
    "vif=pd.DataFrame(vif,index=x_train.columns,columns=['VIF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_逐步回歸 = pd.merge(coef,p_value,left_index=True,right_index=True).merge(vif,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import check_array\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[result])\n",
    "y = np.array(df['新總價'])\n",
    "x = np.array([np.concatenate((v,[1])) for v in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(len(x), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    linreg.fit(x[train],y[train])\n",
    "    p = linreg.predict(x[test])\n",
    "    e = p-y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.exp(y[test])\n",
    "p = np.exp(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "MAPE=mean_absolute_percentage_error(y_test,p).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE=mean_absolute_error(y_test, p).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE=np.sqrt(metrics.mean_squared_error(y_test,p)).round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIT RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hit_Rate_error(y_test,predict_value,alpha):\n",
    "    \n",
    "    df_yp=[]\n",
    "    y_test=pd.DataFrame(y_test,columns=['y_test'])\n",
    "    predict_value=pd.DataFrame(predict_value,columns=['predict_value'])\n",
    "    df_yp = pd.concat([y_test,predict_value],axis=1)#y_test and predict_value\n",
    "    命中值 =[(df_yp['predict_value']<df_yp['y_test']+df_yp['y_test']*alpha)&(df_yp['predict_value']>df_yp['y_test']-df_yp['y_test']*alpha)]\n",
    "    choices = [1]\n",
    "    df_yp['命中值'] = np.select(命中值,choices,default=0)\n",
    "    HIT_rate = (df_yp['命中值'].sum()/len(y_test)*100).round(2)\n",
    "    return HIT_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIT_rate_10=Hit_Rate_error(y_test,p,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIT_rate_20=Hit_Rate_error(y_test,p,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2=r2_score(y_test, p).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:20}{:.4}'.format('R2:', R2))\n",
    "print('{:20}{:.10}'.format('MAPE:', MAPE))\n",
    "print('{:20}{:.10}'.format('MAE:', MAE))\n",
    "print('{:20}{:.10}'.format('RMSE:', RMSE))\n",
    "print('{:20}{:.10}'.format('HIT_rate_10:', HIT_rate_10))\n",
    "print('{:20}{:.10}'.format('HIT_rate_20:', HIT_rate_20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
